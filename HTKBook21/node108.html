<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 3.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>8.5 Embedded Training using HEREST</TITLE>
<META NAME="description" CONTENT="8.5 Embedded Training using HEREST">
<META NAME="keywords" CONTENT="HTKBook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="HTKBook.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html2971" HREF="node109.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html2969" HREF="node103.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html2963" HREF="node107.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html2973" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html2974" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html2972" HREF="node109.html">8.6 Single-Pass Retraining</A>
<B>Up:</B> <A NAME="tex2html2970" HREF="node103.html">8 HMM Parameter Estimation</A>
<B> Previous:</B> <A NAME="tex2html2964" HREF="node107.html">8.4 Isolated Unit Re-Estimation using HREST</A>
<BR> <P>
<H1><A NAME="SECTION03550000000000000000">8.5 Embedded Training using HEREST</A></H1>
<A NAME="seresthmm">&#160;</A>
<P>
<A NAME=8426>&#160;</A>
Whereas isolated unit training is sufficient for  building whole  word
models and initialisation of models using hand-labelled <i>bootstrap</i>
data,  the main HMM training procedures for building sub-word systems
revolve around the  concept of <i>embedded training</i>. Unlike the
processes described so far,  embedded training<A NAME=8429>&#160;</A> simultaneously updates all
of the HMMs in a system using all of the training data.  It is performed by
HEREST<A NAME=8961>&#160;</A> which, unlike HREST, performs just a single iteration.  
<A NAME=8433>&#160;</A>
<P>
In outline, HEREST works as follows.  On startup, HEREST 
loads in a complete
set of HMM definitions.  Every training file must have an associated
label file which gives a transcription for that file.  Only the
sequence of labels is used by HEREST, however, and any boundary location
information is ignored.  Thus, these transcriptions can be generated
automatically from the known orthography of what was said and 
a pronunciation dictionary.
<P>
HEREST processes each training file in turn.  After loading it into memory,
it uses the associated transcription to 
construct a  composite HMM which spans the whole utterance.
This composite HMM is made by concatenating instances of the phone HMMs 
corresponding to each label in the transcription.  The Forward-Backward
algorithm is then applied and the sums needed to form the weighted
averages accumulated in the normal way.  When all of the training
files have been processed, the new parameter estimates are formed
from the weighted sums and the updated HMM set is output.
<A NAME=8438>&#160;</A>
<P>
The mathematical details of embedded Baum-Welch re-estimation
are given below in section&nbsp;<A HREF="node110.html#sbwformulae">8.7</A>.
<P>
In order to use HEREST, it is first necessary to construct a 
file containing a list
of all HMMs in the model set with each model name being written on a separate line.
The names of the models in this<A NAME=8441>&#160;</A>
list must correspond to the labels used in the transcriptions and there
must be a corresponding model for every distinct transcription label.
HEREST is typically invoked by a command line of the form
<PRE>    HERest -S trainlist -I labs -H dir1/hmacs -M dir2 hmmlist</PRE>
where <tt>hmmlist</tt> contains the list of HMMs.  On startup, HEREST will 
load the HMM master macro file (MMF) <tt>hmacs</tt> (there may be
several of these).  It then searches for a definition for each
HMM listed in the <tt>hmmlist</tt>, if any HMM name is not found, 
it attempts to open a file of the same name in the current directory
(or a directory designated by the <tt>-d</tt> option).
Usually in large subword systems, however, all of the HMM definitions
will be stored in MMFs.  Similarly, all of the required transcriptions
will be stored in one or more Master Label Files
<A NAME=8448>&#160;</A> (MLFs), and in the
example, they are stored in the single MLF called <tt>labs</tt>.
<P>
<A NAME="fherestdp">&#160;</A> <IMG WIDTH=367 HEIGHT=352 ALIGN=BOTTOM ALT="tex2html_wrap21614" SRC="img337.gif"  > 
<P>
Once all MMFs and MLFs have been loaded, HEREST processes each file in the
<tt>trainlist</tt>, and accumulates the required statistics as described
above.  On completion, an updated  MMF is output to the directory
<tt>dir2</tt>.  If a second iteration is required, then HEREST is reinvoked
reading in the MMF from <tt>dir2</tt> and outputing 
a new one to <tt>dir3</tt>, and so on.
This process is illustrated by Fig&nbsp;<A HREF="node108.html#fherestdp">8.7</A>.
<P>
When performing embedded training,  it is good practice to
monitor the performance of the models on unseen test data
and stop training when no further improvement is obtained.  Enabling
top level tracing by setting <tt>-T 1</tt> will cause HEREST to
output the overall log likelihood per frame of the training data.
This measure could be used as a termination condition for
repeated application of HEREST.  However, 
repeated re-estimation to convergence<A NAME=8463>&#160;</A> 
may take an impossibly long time.
Worse still, it can lead to over-training since the models can become too
closely matched to the training data and fail to generalise well on unseen
test data.  Hence in practice around 2 to 5 cycles of 
embedded re-estimation are normally sufficient when training phone
models.
<P>
In order to get accurate acoustic models, a large amount of training
data is needed.  Several hundred
utterances are needed for speaker dependent recognition and
several thousand are needed for
speaker independent recognition.  In the latter case, a single
iteration of embedded training
might take several hours to compute.  There are two mechanisms for 
speeding up this computation.  Firstly, HEREST has a pruning
<A NAME=8465>&#160;</A> mechanism
incorporated into its forward-backward computation.  HEREST calculates
the backward probabilities  <IMG WIDTH=30 HEIGHT=22 ALIGN=MIDDLE ALT="tex2html_wrap_inline21596" SRC="img338.gif"  >  first and then the forward probabilities
 <IMG WIDTH=30 HEIGHT=22 ALIGN=MIDDLE ALT="tex2html_wrap_inline21598" SRC="img339.gif"  > .
The full computation of these probabilities for all values of state <I>j</I>
and time <I>t</I> is unnecessary since many of these combinations will be highly
improbable.   On the forward pass, HEREST restricts the computation of
the  <IMG WIDTH=6 HEIGHT=6 ALIGN=BOTTOM ALT="tex2html_wrap_inline21604" SRC="img387.gif"  >  values to just those for which the total log likelihood 
as determined by the product  <IMG WIDTH=61 HEIGHT=22 ALIGN=MIDDLE ALT="tex2html_wrap_inline21606" SRC="img341.gif"  >  is
within a fixed distance from the total likelihood  <IMG WIDTH=53 HEIGHT=23 ALIGN=MIDDLE ALT="tex2html_wrap_inline21608" SRC="img83.gif"  > .  This
pruning is always enabled since it is completely safe and causes no loss
of modelling accuracy.
<P>
Pruning on the backward pass is also possible.
However, in this case, the likelihood product  <IMG WIDTH=61 HEIGHT=22 ALIGN=MIDDLE ALT="tex2html_wrap_inline21610" SRC="img341.gif"  > 
is unavailable since  <IMG WIDTH=30 HEIGHT=22 ALIGN=MIDDLE ALT="tex2html_wrap_inline21612" SRC="img339.gif"  >  has yet to be computed, and hence a 
much broader <I>beam</I> must be set to
avoid pruning errors.  Pruning on the backward path is therefore under
user control. It is set using the <tt>-t</tt> option which has two 
forms.  In the simplest case, a fixed pruning beam is set.  For example,
using <tt>-t 250.0</tt> would set a fixed beam of 250.0.  This method
is adequate when there is sufficient compute time available to 
use a generously wide beam.  When a narrower beam is used, HEREST will 
reject any utterance for which the beam proves to be too narrow.
This can be avoided by using an incremental threshold.  For example,
executing 
<PRE>    HERest -t 120.0 60.0 240.0 -S trainlist -I labs \
           -H dir1/hmacs -M dir2 hmmlist</PRE>
would cause HEREST to run normally
at a beam width<A NAME=8474>&#160;</A> of 120.0.  However, if a pruning 
error<A NAME=8475>&#160;</A> occurs, the
beam is increased by 60.0 and HEREST reprocesses the offending training
utterance.  Repeated errors cause the beam width to be increased
again and this continues until either the utterance is 
successfully processed or the upper beam limit is reached, in this
case 240.0.  Note that errors which occur at very high beam widths
are often caused by transcription errors, hence, it is best not to
set the upper limit too high.
<P>
<A NAME="fparher">&#160;</A> <IMG WIDTH=372 HEIGHT=302 ALIGN=BOTTOM ALT="tex2html_wrap21616" SRC="img345.gif"  > 
<P>
<A NAME=8480>&#160;</A>
The second way of speeding-up the operation of HEREST is to use more than
one computer in parallel.  The way that this is done is to divide the
training data amongst the available machines and then to run HEREST on each
machine such that each invocation of HEREST 
uses the same initial set of models but has its own private set of data.
By setting the option <TT>-p N</TT> where <TT>N</TT> is an integer, HEREST will
dump the contents of all its accumulators<A NAME=8487>&#160;</A>  into a file called <TT>HERN.acc</TT>
rather than updating and outputing a new set of models.  These dumped
files are collected together and input to a new invocation of HEREST with
the option <TT>-p 0</TT> set.  HEREST then reloads the accumulators from
all of the dump files and updates the models in the normal way.
This process is illustrated in Figure&nbsp;<A HREF="node108.html#fparher">8.8</A>.
<P>
To give a concrete example, suppose that four networked workstations
were available to execute the HEREST command given earlier. The training files 
listed previously in <tt>trainlist</tt> would be split 
into four equal sets and a list
of the files in each set stored in <TT>trlist1</TT>, 
<TT>trlist2</TT>, <TT>trlist3</TT>, and <TT>trlist4</TT>.
On the first workstation, the command
<PRE>    HERest -S trlist1 -I labs -H dir1/hmacs -M dir2 -p 1 hmmlist</PRE>
would be executed.  This will load in the HMM definitions in 
<TT>dir1/hmacs</TT>, process the files listed in <TT>trlist1</TT> and finally
dump its accumulators into a file called <TT>HER1.acc</TT> in the output
directory <TT>dir2</TT>.  At the same time, the command
<PRE>    HERest -S trlist2 -I labs -H dir1/hmacs -M dir2 -p 2 hmmlist</PRE>
would be executed on the second workstation, and so on.  When 
HEREST has finished on all four
workstations,  the following command will be executed on just one of them
<PRE>    HERest -H dir1/hmacs -M dir2 -p 0 hmmlist dir2/*.acc</PRE>
where the list of training files has been replaced by the dumped accumulator
files.  This will cause the accumulated
statistics to be reloaded and merged so that the model parameters can
be reestimated and the new model set output to <tt>dir2</tt>
The time to perform this last phase of the operation is very small, hence
the whole process will be around four times quicker than for the
straightforward sequential case.
<P>
<HR><A NAME="tex2html2971" HREF="node109.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html2969" HREF="node103.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html2963" HREF="node107.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html2973" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html2974" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html2972" HREF="node109.html">8.6 Single-Pass Retraining</A>
<B>Up:</B> <A NAME="tex2html2970" HREF="node103.html">8 HMM Parameter Estimation</A>
<B> Previous:</B> <A NAME="tex2html2964" HREF="node107.html">8.4 Isolated Unit Re-Estimation using HREST</A>
<P><ADDRESS>
ECRL HTK_V2.1: email support@entropic.com
</ADDRESS>
</BODY>
</HTML>
