<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 3.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>3.3.2 Step 10 - Making Tied-State Triphones</TITLE>
<META NAME="description" CONTENT="3.3.2 Step 10 - Making Tied-State Triphones">
<META NAME="keywords" CONTENT="HTKBook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="HTKBook.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html1891" HREF="node34.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html1889" HREF="node31.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html1885" HREF="node32.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html1893" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html1894" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html1892" HREF="node34.html">3.4 Recogniser Evaluation</A>
<B>Up:</B> <A NAME="tex2html1890" HREF="node31.html">3.3 Creating Tied-State Triphones</A>
<B> Previous:</B> <A NAME="tex2html1886" HREF="node32.html">3.3.1 Step 9 - Making Triphones from Monophones</A>
<BR> <P>
<H2><A NAME="SECTION02332000000000000000">3.3.2 Step 10 - Making Tied-State Triphones</A></H2>
<P>
The outcome of the previous stage is a set of triphone HMMs with all triphones
in a phone set sharing the same transition matrix.  When estimating these
models, many of the variances in the output distributions
will have been floored since there will be<A NAME=2301>&#160;</A><A NAME=2302>&#160;</A>
<A NAME=2303>&#160;</A><A NAME=2304>&#160;</A>
insufficient data associated with many of the states.  The last step in
the model building process is to tie states within triphone sets
in order to share data and thus be able to make robust parameter estimates.
<P>
In the previous step, the <tt>TI</tt> command was used to
explicitly tie all members of a set of transition matrices together. 
However,
the choice of which states to tie requires a bit more  subtlety since
the performance of the recogniser depends crucially on how accurate
the state output distributions capture the statistics of the speech data.
<P>
HHED provides two mechanisms which allow states to be clustered 
and<A NAME=2307>&#160;</A>
then each cluster tied.  The first is data-driven and uses a similarity
measure between states.  The second uses decision trees<A NAME=2308>&#160;</A>
and is based on asking questions about the left and right contexts of each
triphone.  The decision tree attempts to find those contexts which make the largest
difference to the acoustics and which should therefore distinguish clusters.
<P>
Decision tree state tying is performed by running HHED 
in the normal way, i.e.
<PRE>   HHEd -B -H hmm12/macros -H hmm12/hmmdefs -M hmm13 \
        tree.hed triphones1 &gt; log</PRE>
Notice that the output is saved in a log file.  This is important since
some tuning of thresholds is usually needed.
<P>
The edit script <tt>tree.hed</tt>, which contains the instructions regarding
which contexts to examine for possible clustering, can be rather long and
complex. A script for automatically generating this file, <tt>mkclscript</tt>,
is found in the RM Demo. A version of the <tt>tree.hed</tt> script, which can
be used with this tutorial, is included in the <tt>HTKTutorial</tt> directory.
The entire script appropriate for clustering English phone models is too long
to show here in the text, however, its main components are given by the
following fragments:
<P>
<PRE>    RO 100.0 stats
    TR 0
    QS &quot;L_Class-Stop&quot; {p-*,b-*,t-*,d-*,k-*,g-*} 
    QS &quot;R_Class-Stop&quot; {*+p,*+b,*+t,*+d,*+k,*+g} 
    QS &quot;L_Nasal&quot; {m-*,n-*,ng-*} 
    QS &quot;R_Nasal&quot; {*+m,*+n,*+ng}
    QS &quot;L_Glide&quot; {y-*,w-*} 
    QS &quot;R_Glide&quot; {*+y,*+w}
    ....
    QS &quot;L_w&quot; {w-*} 
    QS &quot;R_w&quot; {*+w} 
    QS &quot;L_y&quot; {y-*} 
    QS &quot;R_y&quot; {*+y} 
    QS &quot;L_z&quot; {z-*} 
    QS &quot;R_z&quot; {*+z} 
 
    TR 2

    TB 350.0 &quot;aa_s2&quot; {(aa, *-aa, *-aa+*, aa+*).state[2]}
    TB 350.0 &quot;ae_s2&quot; {(ae, *-ae, *-ae+*, ae+*).state[2]}
    TB 350.0 &quot;ah_s2&quot; {(ah, *-ah, *-ah+*, ah+*).state[2]}
    TB 350.0 &quot;uh_s2&quot; {(uh, *-uh, *-uh+*, uh+*).state[2]}
    ....
    TB 350.0 &quot;y_s4&quot; {(y, *-y, *-y+*, y+*).state[4]}
    TB 350.0 &quot;z_s4&quot; {(z, *-z, *-z+*, z+*).state[4]}
    TB 350.0 &quot;zh_s4&quot; {(zh, *-zh, *-zh+*, zh+*).state[4]}

    TR 1
    
    AU &quot;fulllist&quot;
    CO &quot;tiedlist&quot;

    ST &quot;trees&quot;</PRE>
Firstly, the <tt>RO</tt><A NAME=2454>&#160;</A> command is used to set
the outlier threshold<A NAME=2316>&#160;</A> to 100.0 and load the statistics
file<A NAME=2317>&#160;</A> generated at the end of the previous step.  The
outlier threshold determines the minimum occupancy<A NAME=2318>&#160;</A> of
any cluster and prevents a single outlier state forming a singleton cluster
just because it is acoustically very different to all the other states.  The
<tt>TR</tt><A NAME=2455>&#160;</A> command sets the trace level to zero
in preparation for loading in the questions.  Each
<tt>QS</tt><A NAME=2456>&#160;</A> command loads a single question and
each question is defined by a set of contexts.  For example, the first
<tt>QS</tt> command defines a question called <tt>L_Class-Stop</tt> which is
true if the left context is either of the stops <tt>p</tt>,
<tt>b</tt>, <tt>t</tt>, <tt>d</tt>, <tt>k</tt> or <tt>g</tt>.
<P>
Notice that for a triphone system, it is necessary to include questions
referring to both the right and left contexts of a phone. The questions should
progress from wide, general classifications (such as consonant, vowel, nasal,
diphthong, etc.) to specific instances of each phone.
Ideally, the full set of questions loaded using the <tt>QS</tt> command would
include every possible context which can influence the acoustic realisation of
a phone, and can include any linguistic or phonetic classification which may be
relevant. There is no harm in creating extra unnecessary questions, because
those which are determined to be irrelevant to the data will be ignored.
<P>
The second <tt>TR</tt> command enables intermediate level progress reporting so
that each of the following <tt>TB</tt> commands<A NAME=2457>&#160;</A>
can<A NAME=2335>&#160;</A> be monitored.  Each of these <tt>TB</tt> commands
clusters one specific set of states.  For example, the first <tt>TB</tt>
command applies to the first emitting state of all context-dependent models for
the phone <tt>aa</tt>.
<P>
Each <tt>TB</tt> command works as follows.  Firstly, each set of states defined
by the final argument is pooled to form a single cluster.  Each question in the
question set loaded by the <tt>QS</tt> commands is used to split the pool into
two sets.  The use of two sets rather than one, allows the log likelihood of
the training data to be increased and the question which maximises this
increase is selected for the first branch of the tree. The process is then
repeated until the increase in log likelihood achievable by any question at any
node is less than the threshold specified by the first argument (350.0 in this
case).
<P>

<A NAME="fstep10">&#160;</A> <IMG WIDTH=193 HEIGHT=387 ALIGN=BOTTOM ALT="tex2html_wrap19818" SRC="img124.gif"  > 
<P>
Note that the values given in the <tt>RO</tt> and <tt>TB</tt> commands affect
the degree of tying and therefore the number of states output in the clustered
system.  The values should be varied according to the amount of training data
available.
As a final step to the clustering, any pair of clusters which can be merged
<A NAME=2898>&#160;</A> such that the decrease in log likelihood is below
the threshold is merged.  On completion, the states in each cluster <I>i</I> are
tied to form a single shared state with macro name <tt>xxx_i</tt> where
<tt>xxx</tt> is the name given by the second argument of the <tt>TB</tt>
command.
<P>
The set of triphones used so far only includes those needed to cover the
training data. The <tt>AU</tt> command takes as its argument a new list of
triphones expanded to include all those needed for recognition.  This list can
be generated, for example, by using HDMAN on the entire dictionary (not
just the training dictionary), converting it to triphones using the command
<tt>TC</tt> and outputting a list of the distinct triphones to a file using the
option <tt>-n</tt>
<P>

<P>
<PRE>    HDMan -n fulllist -l flog beep</PRE>
<P>
The effect of the <tt>AU</tt> command is to use the decision trees to
synthesise all of the new previously unseen triphones in the new list.
<A NAME=2459>&#160;</A>
<P>
Once all state-tying has been completed and new models synthesised, 
some models may  share exactly
the same 3 states and transition matrices and are thus identical.
The <tt>CO</tt> command<A NAME=2460>&#160;</A><A NAME=2359>&#160;</A> is used
to compact the model set by finding all identical models and tying them
together<A NAME="tex2html224" HREF="footnode.html#2461"><IMG  ALIGN=BOTTOM ALT="gif" SRC="foot_motif.gif"></A>, producing a new list of models
called <tt>tiedlist</tt>.
<P>
One of the advantages of using decision tree clustering is that it allows
previously<A NAME=2362>&#160;</A>
unseen triphones to be synthesised.  To do this, the trees must
be saved and this is done by the <tt>ST</tt> command<A NAME=2462>&#160;</A>.
Later if new previously unseen triphones are required, for example in the
pronunciation of a new vocabulary item, the existing model set can be
reloaded into HHED, the trees reloaded using 
the <tt>LT</tt> command<A NAME=2463>&#160;</A>
and then a new extended list of triphones created using 
the <tt>AU</tt> command.<A NAME=2464>&#160;</A>
<P>
After HHED has completed,  the effect of tying can be studied and
the thresholds adjusted if necessary.  The log file will
include summary statistics which give the total number of physical
states remaining and the number of models after compacting.
<P>
Finally, and for the last time, the models are reestimated twice using
HEREST.  Fig.&nbsp;<A HREF="node33.html#fstep10">3.14</A> illustrates this last step in the HMM
build process.  The trained models are then contained in the file
<tt>hmm15/hmmdefs</tt>.
<P>
<HR><A NAME="tex2html1891" HREF="node34.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html1889" HREF="node31.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html1885" HREF="node32.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html1893" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html1894" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html1892" HREF="node34.html">3.4 Recogniser Evaluation</A>
<B>Up:</B> <A NAME="tex2html1890" HREF="node31.html">3.3 Creating Tied-State Triphones</A>
<B> Previous:</B> <A NAME="tex2html1886" HREF="node32.html">3.3.1 Step 9 - Making Triphones from Monophones</A>
<P><ADDRESS>
ECRL HTK_V2.1: email support@entropic.com
</ADDRESS>
</BODY>
</HTML>
