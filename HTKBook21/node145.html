<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 3.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>12.7 N-Best Lists and Lattices</TITLE>
<META NAME="description" CONTENT="12.7 N-Best Lists and Lattices">
<META NAME="keywords" CONTENT="HTKBook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="HTKBook.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html3432" HREF="node146.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html3430" HREF="node138.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html3426" HREF="node144.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html3434" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html3435" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html3433" HREF="node146.html">Part III: Reference Section</A>
<B>Up:</B> <A NAME="tex2html3431" HREF="node138.html">12 Decoding</A>
<B> Previous:</B> <A NAME="tex2html3427" HREF="node144.html">12.6 Recognition using Direct Audio Input</A>
<BR> <P>
<H1><A NAME="SECTION03970000000000000000">12.7 N-Best Lists and Lattices</A></H1>
<A NAME="snbest">&#160;</A>
<P>
<A NAME=11376>&#160;</A>
As noted in section&nbsp;<A HREF="node139.html#sdecop">12.1</A>, HVITE can generate 
lattices<A NAME=11379>&#160;</A>
and N-best<A NAME=11380>&#160;</A> outputs.  To generate an N-best list, the <tt>-n</tt> option
is used to specify the number of N-best tokens to store per state and
the number of N-best hypotheses to generate.  The result is that
for each input utterance, a multiple alternative 
transcription<A NAME=11382>&#160;</A> is generated.
For example, setting <tt>-n 4 20</tt> with a digit 
recogniser would generate an output of the form
<PRE>    &quot;testf1.rec&quot;
    FOUR
    SEVEN
    NINE
    OH
    /// 
    FOUR
    SEVEN
    NINE
    OH
    OH
    /// 

    etc</PRE>
<P>
The lattices from which the N-best lists are generated can be output by setting
the option <tt>-z ext</tt>.  In this case, a lattice called <tt>testf.ext</tt> will
be generated for each input test file <tt>testf.xxx</tt>.  By default, these lattices
will  be stored in the same directory as the test files, but they can be redirected
to another directory using the <tt>-l</tt> option.
<P>
<A NAME=11388>&#160;</A>
The lattices generated by HVITE have the following general form
<PRE>    VERSION=1.0
    UTTERANCE=testf1.mfc
    lmname=wdnet
    lmscale=20.00  wdpenalty=-30.00
    vocab=dict
    N=31   L=56   
    I=0    t=0.00  
    I=1    t=0.36  
    I=2    t=0.75  
    I=3    t=0.81
    ... etc
    I=30   t=2.48  
    J=0     S=0    E=1    W=SILENCE   v=0  a=-3239.01  l=0.00    
    J=1     S=1    E=2    W=FOUR      v=0  a=-3820.77  l=0.00    
    ... etc
    J=55    S=29   E=30   W=SILENCE   v=0  a=-246.99   l=-1.20</PRE>
<P>
The first 5 lines comprise a header which records names of the files used to
generate the lattice along with the settings of the language model scale and
penalty factors. Each node in the lattice represents a point in time measured in
seconds and each arc represents a word spanning the segment of the input
starting at the time of its start node and ending at the time of its end node.  
For each such span, <tt>v</tt> gives the number of the pronunciation used, 
<tt>a</tt> gives the acoustic score and <tt>l</tt> gives the language model
score.
<P>
The language model scores in output lattices do not include the scale factors
and penalties.  These are removed so that the lattice can be used as a
constraint network for subsequent recogniser testing.  When using HVITE
normally, the word level network file is specified using the <tt>-w</tt>
option.  When the <tt>-w</tt> option is included but no file name is included,
HVITE constructs the name of a lattice file from the name of the test
file and inputs that.  Hence, a new recognition network is created for each
input file and recognition is very fast.  For example, this is an efficient way
of experimentally determining optimum values for the language 
model scale<A NAME=11397>&#160;</A> and
penalty factors.
<P>
<HR><A NAME="tex2html3432" HREF="node146.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html3430" HREF="node138.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html3426" HREF="node144.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html3434" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html3435" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html3433" HREF="node146.html">Part III: Reference Section</A>
<B>Up:</B> <A NAME="tex2html3431" HREF="node138.html">12 Decoding</A>
<B> Previous:</B> <A NAME="tex2html3427" HREF="node144.html">12.6 Recognition using Direct Audio Input</A>
<P><ADDRESS>
ECRL HTK_V2.1: email support@entropic.com
</ADDRESS>
</BODY>
</HTML>
