<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 3.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>8.1 Training Strategies</TITLE>
<META NAME="description" CONTENT="8.1 Training Strategies">
<META NAME="keywords" CONTENT="HTKBook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="HTKBook.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html2923" HREF="node105.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html2921" HREF="node103.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html2915" HREF="node103.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html2925" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html2926" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html2924" HREF="node105.html">8.2 Initialisation using HINIT</A>
<B>Up:</B> <A NAME="tex2html2922" HREF="node103.html">8 HMM Parameter Estimation</A>
<B> Previous:</B> <A NAME="tex2html2916" HREF="node103.html">8 HMM Parameter Estimation</A>
<BR> <P>
<H1><A NAME="SECTION03510000000000000000">8.1 Training Strategies</A></H1>
<A NAME="ststrats">&#160;</A>
<P>
As indicated in the introduction above, the basic operation of 
the HTK training tools
involves  reading in a set of one or more HMM definitions, and then using
speech data to estimate the parameters of  these definitions.  The speech
data files are normally stored in parameterised form such as <tt>LPC</tt> or 
<tt>MFCC</tt>
parameters.  However, additional parameters such as delta coefficients are
normally computed <i>on-the-fly</i> whilst loading each file.
<P>

<A NAME="fisoword">&#160;</A> <IMG WIDTH=242 HEIGHT=391 ALIGN=BOTTOM ALT="tex2html_wrap21584" SRC="img331.gif"  > 
<P>
In fact,
it is also possible to use waveform data directly by performing the full parameter
conversion <i>on-the-fly</i>.  Which approach is preferred depends on the
available computing resources.  The advantages of storing the data already
encoded are that the data is more compact in parameterised form  and pre-encoding
avoids wasting compute time converting the data each time that it is read
in.  However, if the training data is derived from CD-ROMS and they can be
accessed automatically on-line, then the extra compute may be worth the
saving in magnetic disk storage.<A NAME=9081>&#160;</A>
<P>
The methods for configuring speech data
input to HTK tools were described in detail in chapter&nbsp;<A HREF="node50.html#cspeechio">5</A>.
All of the various input mechanisms are supported by the HTK training
tools except direct audio input.
<P>
The precise way in which the training tools are  used depends on the
type of HMM system to be built and the form of the available
training data. Furthermore,
HTK tools are designed to interface cleanly to each other, so a
large number of configurations are possible.  In practice, however,
HMM-based  speech recognisers are either whole-word or sub-word.
<P>

<P>
As the name suggests,  whole word modelling<A NAME=8241>&#160;</A> refers to a technique
whereby each individual word in the system vocabulary is modelled by
a  single HMM.  As shown in Fig.&nbsp;<A HREF="node104.html#fisoword">8.1</A>, whole word HMMs
are most commonly trained on examples of each word spoken in
isolation.  If these training examples, which are often called
<i>tokens</i>, have had leading and trailing silence removed, then
they can be input directly into the training tools without the need
for any label information. The most common method of building whole
word HMMs is to firstly use
HINIT<A NAME=8943>&#160;</A> to calculate initial 
parameters for the model and then
use
HREST<A NAME=8944>&#160;</A> to refine the parameters using Baum-Welch
re-estimation. Where there is limited training data and recognition
in adverse noise environments is needed, so-called <I>fixed
variance</I> models can offer improved robustness. These are models in
which all the variances are set equal to 
the global speech variance<A NAME=8249>&#160;</A>
and never subsequently re-estimated.  The tool
HCOMPV<A NAME=8945>&#160;</A> can be used to 
compute this global variance.
<A NAME=8252>&#160;</A>
<P>
<A NAME="fsubword">&#160;</A> <IMG WIDTH=372 HEIGHT=499 ALIGN=BOTTOM ALT="tex2html_wrap21586" SRC="img332.gif"  > 
<P>
Although HTK gives full support for building whole-word
HMM systems, the bulk of its facilities are focussed on 
building sub-word systems in which the basic units are the
individual sounds of the language called <i>phones</i>.
One HMM is constructed for each such phone<A NAME=8257>&#160;</A> and 
continuous speech<A NAME=8258>&#160;</A> 
is recognised by joining the phones together to 
make any required vocabulary using a pronunciation dictionary.
<P>
<A NAME=8259>&#160;</A>
The basic procedures involved in training a set of subword models
are shown in Fig.&nbsp;<A HREF="node104.html#fsubword">8.2</A>.  The core process involves the
embedded training<A NAME=8261>&#160;</A> tool 
HEREST<A NAME=8946>&#160;</A>.  HEREST uses 
continuously spoken utterances as its source of training data
and simultaneously re-estimates the complete set of subword HMMs.
For each input utterance, HEREST needs a transcription i.e. a list of
the phones in that utterance.  HEREST then joins together all of the 
subword HMMs corresponding to this phone list to make a single
composite HMM.  This composite HMM is used to collect
the necessary statistics for the re-estimation.  When all of the
training utterances have been processed, the total set of accumulated
statistics are used to re-estimate the parameters of all of the phone
HMMs. 
It is important to emphasise that in the above process, the transcriptions
are only needed to identify the sequence of phones in each utterance.
No phone boundary information is needed.
<P>
The initialisation<A NAME=8267>&#160;</A> of a 
set of phone HMMs prior to embedded re-estimation
using HEREST can be achieved in two different ways.  As shown on the
left of Fig.&nbsp;<A HREF="node104.html#fsubword">8.2</A>, a small set of hand-labelled 
<i>bootstrap</i> training data can be used along with<A NAME=8271>&#160;</A>
the isolated training tools HINIT and HREST to
initialise each phone HMM individually.  When used in this way,
both HINIT and HREST use the label information
to extract all the segments of speech corresponding to the current
phone HMM in order to perform isolated word training.
<P>
A simpler initialisation procedure uses HCOMPV to assign the global
speech mean and variance to every Gaussian distribution in every phone
HMM.  This so-called <i>flat start</i> procedure implies that during the
first cycle of embedded re-estimation, each training utterance will be
uniformly segmented.  The hope then is that enough of the phone models
align with actual realisations of that phone so that on the second and
subsequent iterations, the models align as intended.<A NAME=8278>&#160;</A>
<P>
One of the major problems to be faced in building any HMM-based
system is that the amount of training data for each model will be
variable and is rarely sufficient.  To overcome this, HTK allows
a variety of sharing mechanisms to be implemented whereby HMM parameters
are tied together so that the training data is pooled and more robust
estimates result.  These tyings, along with a variety of other
manipulations, are performed using the  HTK HMM editor HHED.
The use of HHED<A NAME=8947>&#160;</A> is 
described in a later chapter.  Here it is
sufficient to note that a phone-based HMM set typically goes through
several refinement cycles of editing using HHED followed
by parameter re-estimation using HEREST before the final model set is
obtained.
<P>
Having described in outline the main training strategies, each
of the above procedures will be described in more detail.
<P>
<HR><A NAME="tex2html2923" HREF="node105.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next_motif.gif"></A> <A NAME="tex2html2921" HREF="node103.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up_motif.gif"></A> <A NAME="tex2html2915" HREF="node103.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="previous_motif.gif"></A> <A NAME="tex2html2925" HREF="node1.html"><IMG WIDTH=65 HEIGHT=24 ALIGN=BOTTOM ALT="contents" SRC="contents_motif.gif"></A> <A NAME="tex2html2926" HREF="node263.html"><IMG WIDTH=43 HEIGHT=24 ALIGN=BOTTOM ALT="index" SRC="index_motif.gif"></A> <BR>
<B> Next:</B> <A NAME="tex2html2924" HREF="node105.html">8.2 Initialisation using HINIT</A>
<B>Up:</B> <A NAME="tex2html2922" HREF="node103.html">8 HMM Parameter Estimation</A>
<B> Previous:</B> <A NAME="tex2html2916" HREF="node103.html">8 HMM Parameter Estimation</A>
<P><ADDRESS>
ECRL HTK_V2.1: email support@entropic.com
</ADDRESS>
</BODY>
</HTML>
